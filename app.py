import streamlit as st
import ollama
from core.rag_pipeline import RAGClient
from core.utils import *
from core.reader import read_pdf
from langchain_text_splitters import RecursiveCharacterTextSplitter
from core.config import *

st.set_page_config(page_title='Local RAG', page_icon='ü§ñ')

@st.cache_resource
def get_rag(llm_model):
    return RAGClient(llm_model=llm_model)

try:
    models_list = [m['model'] for m in ollama.list()['models']]
except Exception:
    models_list = [LLM_MODEL]

with st.sidebar:
    model_selector = st.selectbox('–í—ã–±–µ—Ä–∏ –º–æ–¥–µ–ª—å', models_list)
    rag = get_rag(model_selector)
    
    file = st.file_uploader('–ó–∞–≥—Ä—É–∑–∏ –¥–æ–∫—É–º–µ–Ω—Ç (PDF)', type='pdf')
    if file:
        if 'last_uploaded' not in st.session_state or st.session_state.last_uploaded != file.name:
            with st.spinner('–ß–∏—Ç–∞—é –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É—é –¥–æ–∫—É–º–µ–Ω—Ç...'):
                file_path = save_uploaded_file(file)
                pdf = read_pdf(file_path)
                
                if len(pdf) < 50:
                    st.error('–§–∞–π–ª –ø—É—Å—Ç–æ–π –∏–ª–∏ —ç—Ç–æ —Å–∫–∞–Ω (–∫–∞—Ä—Ç–∏–Ω–∫–∞). –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.')
                    if os.path.exists(file_path): os.remove(file_path)
                    st.stop()
                    
                text_splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)
                chunks = text_splitter.split_text(pdf)
                rag.build_indices(chunks)
                st.success('–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –æ–±–Ω–æ–≤–ª–µ–Ω–∞!')
                st.session_state.last_uploaded = file.name
                
    
    
    reset_btn = st.button('–û—á–∏—Å—Ç–∏—Ç—å –±–∞–∑—É')
    if reset_btn:
        with st.spinner("–û—á–∏—â–∞—é –¥–∞–Ω–Ω—ã–µ..."):
            rag.reset_database()
            
            clear_database()

            st.cache_resource.clear()
            st.session_state.clear()
            st.rerun()
            
if 'messages' not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg['role']):
        st.write(msg['content'])

prompt = st.chat_input('–¢–≤–æ–π —Ç–µ–∫—Å—Ç')

if prompt:
    st.session_state.messages.append({'role': 'user', 'content': prompt})
    with st.chat_message('user'):
        st.write(prompt)

    with st.spinner('–î—É–º–∞—é...'):
        new_query = rag.contextualize_query(prompt, st.session_state.messages[:-1])
        st.write(f'üîÑ *–ò—â—É: {new_query}*')
        
        context_list = rag.query(new_query)
        
        if context_list:
            context = '\n---\n'.join(context_list)
            response = rag.generate_answer(context, new_query)
        else:
            response = '–Ø –ø–æ–∫–∞ –Ω–∏—á–µ–≥–æ –Ω–µ –∑–Ω–∞—é. –ó–∞–≥—Ä—É–∑–∏ –¥–æ–∫—É–º–µ–Ω—Ç –≤ –º–µ–Ω—é —Å–ª–µ–≤–∞!'
            context = '–ù–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞'
    
    st.session_state.messages.append({'role': 'assistant', 'content': response})
    with st.chat_message('assistant'):
        st.write(response)
        
    with st.expander(f'–ò—Å—Ç–æ—á–Ω–∏–∫–∏ (–ù–∞–π–¥–µ–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {len(context_list)})'):
        for i, doc in enumerate(context_list): 
            st.markdown(f'**–§—Ä–∞–≥–º–µ–Ω—Ç #{i+1}**')
            st.info(doc)